<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Restricted Boltzmann Machine Visualizations</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>RBM Visualizations</h1>
        <h2>Renders of RBM Activations, Weight Histograms, and Learned Filters</h2>
        <a href="https://github.com/jpatanooga/Metronome" class="button"><small>View project on</small>GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>

<a name="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages"><span class="octicon octicon-link"></span></a>Renders from March 06, 2014.</h3>

<p>Something interesting that Hinton has proposed is that <b>we can take a look about what machines "dream about"</b> in their sleep state.</p>

<p>
In the spirit of reproducing good research to baseline our implementation, we've visualiezed our RBMs based on the techniques from Yosinski and Lipson's paper:
</p>

</p>
"Visually Debugging Restricted Boltzmann Machine Training with a 3D Example"

<a href="http://yosinski.com/media/papers/Yosinski2012VisuallyDebuggingRestrictedBoltzmannMachine.pdf">http://yosinski.com/media/papers/Yosinski2012VisuallyDebuggingRestrictedBoltzmannMachine.pdf</a>
</p>

<p>
Below is a sampling from the renders taken from our Deep Learning implementation of Restricted Boltzmann Machines in Metronome. In these renders the RBMs are learning reprensetations of the canonical <a href="http://yann.lecun.com/exdb/mnist/">MNIST Dataset</a>. As you can see in the learned filter, portions of digits are clearly visible.
</p>

<h4>Filter Renders</h4>

<blockquote> ...we plot the learned filter for each hidden neuron, one per column of W. Each filter is of the same dimension as the input data, and it is most useful to visualize the filters in the same way
as the input data is visualized. In the cases of image patches, we show each filter as an image patch...</blockquote>

<p>

<table>
<tr>
<td>
Starting state for filters
</td>
<td>
Filters at 206 Cross Entropy
</td>
<td>
Filters at 4.9 Cross Entropy
</td>
<tr>

<tr>
<td>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/filters_init_ce.png" />
</td>
<td>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/filters_206.7_ce.png" />
</td>
<td>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/filters_4.996_ce.png" />
</td>
</tr>
</table>

</p>

<h4>Activation Renders</h4>

<blockquote>...we plot this probability of activation for each hidden neuron...</blockquote>


<p>
At Initialization Time:
</p>
<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/activations_init_ce.png" />
</p>

<p>
At 206 Cross Entropy:
</p>
<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/activations_206.7_ce.png" />
</p>

<p>
At 78 Cross Entropy:
</p>
<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/activations_78.52_ce.png" />
</p>

<p>
At 4.9 Cross Entropy:
</p>
<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/activations_4.996_ce.png" />
</p>

<h4>Weight Histogram Renders</h4>

<p>A look at how the connection weights in the RBMs change during training in the form of a weight histogram.</p>


<p>
At Initialization Time:
</p>

<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/weight_histogram_init_ce.png" />

</p>

<p>
At 4.9 Cross Entropy:
</p>
<p>
<img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/weight_histogram_4.996_ce.png" />

</p>

<h4>The Dream State of a Machine</h4>

<p>So what do all these visualization drive? What we want from the RBMs in Deep Learning is for them to learn progressively higher level representations
of the input dataset in the pre-train phase. So we want to know what the machine "dreams" when we stimulate it with a certain input.</p>

<p>Take a look at how Hinton explains the dream states of RBMS: [video]</p>

<table>

<tr>

<td>Cross Entropy</td>
<td>The "0" Digit</td>
<td>The "1" Digit</td>
<td>The "3" Digit</td>
<td>The "5" Digit</td>
<td>The "9" Digit</td>

</tr>

<tr>

<td>Input Data</td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/0/0_real.png" style="width:112; height:112;" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/1/1_real.png" style="width:112; height:112;" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/3/3_real.png" style="width:112; height:112;" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/5/5_real.png" style="width:112; height:112;" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/9/9_real.png" style="width:112; height:112;" /></td>

</tr>

<tr>

<td>Cross Entropy 206</td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/0/206.7_ce_0_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/1/206.7_ce_1_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/3/206.7_ce_3_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/5/206.7_ce_5_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/9/206.7_ce_9_test.png" /></td>

</tr>


<tr>

<td>Cross Entropy 140</td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/0/140.0_ce_0_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/1/140.0_ce_1_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/3/140.0_ce_3_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/5/140.0_ce_5_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/9/140.0_ce_9_test.png" /></td>

</tr>


<tr>

<td>Cross Entropy 78</td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/0/78.52_ce_0_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/1/78.52_ce_1_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/3/78.52_ce_3_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/5/78.52_ce_5_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/9/78.52_ce_9_test.png" /></td>

</tr>



<tr>

<td>Cross Entropy 4</td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/0/4.996_ce_0_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/1/4.996_ce_1_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/3/4.996_ce_3_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/5/4.996_ce_5_test.png" /></td>
<td><img src="https://raw.github.com/jpatanooga/jpatanooga.github.io/master/images/deeplearning/rbm20140306/9/4.996_ce_9_test.png" /></td>

</tr>

</table>


<p>
If this kind of ML is your cup of tea then take a minute to <a href="https://hadoopsummit.uservoice.com/forums/242804-data-science-hadoop-track/suggestions/5568291-introduction-to-deep-learning-on-hadoop">Vote for us at Hadoop Summit 2014</a>!
</p>

      </div>
    </div>

  
  </body>
</html>
